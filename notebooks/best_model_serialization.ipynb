{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a53650b-578b-4a8d-a068-45a04085d941",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24d68e5-a3e9-40fe-a2ff-043064c6d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fb3f6-a96a-4a3d-af3e-cf76b6790fd4",
   "metadata": {},
   "source": [
    "# Query of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c262c8c9-e625-4071-98ec-8a2f7f1fa1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/15 09:54:16 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/15 09:54:16 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/15 09:54:16 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/15 09:54:16 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/15 09:54:17 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/15 09:54:17 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow client\n",
    "client = MlflowClient()\n",
    "MODEL_NAME = Config.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fc10b0-3be5-4439-a8e5-98ec9b18d3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/15 09:54:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/15 09:54:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/15 09:54:17 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/15 09:54:17 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 registered model versions\n",
      "Version 6 - Run ID: b679c3a119f04be4bf3d4ba4493dd3db\n",
      "Version 5 - Run ID: 5cc5462ecdb84e5db9b0bae6f05a77a1\n",
      "Version 4 - Run ID: 60f2b233c0704edc8d65b882ba6f356a\n",
      "Version 3 - Run ID: 1d27b375f1aa4216889c338c375ef351\n",
      "Version 2 - Run ID: d8f7941bcefb410b9f8b115ba7a5dfa0\n",
      "Version 1 - Run ID: b6789d4cd1174d959af79611ae26f488\n"
     ]
    }
   ],
   "source": [
    "# Get all versions of the registered model\n",
    "model_versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "\n",
    "print(f\"Found {len(model_versions)} registered model versions\")\n",
    "for version in model_versions:\n",
    "    print(f\"Version {version.version} - Run ID: {version.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752459ea-a089-413b-a08d-6c6d6d48726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 6 - Run ID: b679c3a119f04be4bf3d4ba4493dd3db - Test Acc: 0.9891\n",
      "Version 5 - Run ID: 5cc5462ecdb84e5db9b0bae6f05a77a1 - Test Acc: 0.9875\n",
      "Version 4 - Run ID: 60f2b233c0704edc8d65b882ba6f356a - Test Acc: 0.9891\n",
      "Version 3 - Run ID: 1d27b375f1aa4216889c338c375ef351 - Test Acc: 0.9876\n",
      "Version 2 - Run ID: d8f7941bcefb410b9f8b115ba7a5dfa0 - Test Acc: 0.9876\n",
      "Version 1 - Run ID: b6789d4cd1174d959af79611ae26f488 - Test Acc: 0.9891\n",
      "\n",
      "Best model: Version 6\n",
      "Run ID: b679c3a119f04be4bf3d4ba4493dd3db\n",
      "Test Accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "best_version = None\n",
    "best_f1_score = -1\n",
    "\n",
    "for version in model_versions:\n",
    "    run_id = version.run_id\n",
    "    run = client.get_run(run_id)\n",
    "    metrics = run.data.metrics\n",
    "    \n",
    "    # Get metrics\n",
    "    test_f1_score = metrics.get('test_f1_score', -1)\n",
    "    \n",
    "    print((\n",
    "        f\"Version {version.version} - \"\n",
    "        f\"Run ID: {run_id} - \"\n",
    "        f\"Test Acc: {test_f1_score:.4f}\"\n",
    "    ))\n",
    "    \n",
    "    if test_f1_score > best_f1_score:\n",
    "        best_f1_score = test_f1_score\n",
    "        best_version = version\n",
    "\n",
    "print(f\"\\nBest model: Version {best_version.version}\")\n",
    "print(f\"Run ID: {best_version.run_id}\")\n",
    "print(f\"Test Accuracy: {best_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49375365-7e44-4252-9128-7b5aaa99619a",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f031a26-58de-4496-8c45-1fae16346eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928bcd609c5e42b8b6e11d4bdd3b1abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8230b57ac04c1d963a58928c643884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and moved to CPU\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_uri = f\"runs:/{best_version.run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "\n",
    "# Move to CPU and set to evaluation mode\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully and moved to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28debf5-e0c6-43ca-b17f-57d144f7d2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233397/212904453.py:6: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 105 of general pattern rewrite rules.\n",
      "Converting to embedded format...\n",
      "Removed cats_and_dogs_mobilenet_v2_b679c3.onnx.data\n",
      "Model serialized to cats_and_dogs_mobilenet_v2_b679c3.onnx (embedded weights)\n"
     ]
    }
   ],
   "source": [
    "# dummy input for ONNX export\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export to ONNX\n",
    "onnx_model_path = f\"{Config.MODEL_NAME}_{best_version.run_id[0:6]}.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_model_path,\n",
    "    export_params=True,\n",
    "    opset_version=18,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "# Convert external data to embedded format\n",
    "print(\"Converting to embedded format...\")\n",
    "onnx_model = onnx.load(onnx_model_path, load_external_data=True)\n",
    "onnx.save(onnx_model, onnx_model_path)\n",
    "\n",
    "# Remove the external data file if it exists\n",
    "external_data_path = onnx_model_path + \".data\"\n",
    "if os.path.exists(external_data_path):\n",
    "    os.remove(external_data_path)\n",
    "    print(f\"Removed {external_data_path}\")\n",
    "\n",
    "print(f\"Model serialized to {onnx_model_path} (embedded weights)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b7c3c-cda9-4ad3-9939-e748a9fb0333",
   "metadata": {},
   "source": [
    "# Class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be33859b-65c9-45cc-a8de-d722bc7a3e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a7ab931d6449fbb99d7acf88fcbf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels downloaded to: /tmp/tmpnv4uefhq/labels.json\n",
      "Class labels saved to cats_and_dogs_mobilenet_v2_b679c3_labels.json\n",
      "Params saved to cats_and_dogs_mobilenet_v2_b679c3_labels.json\n"
     ]
    }
   ],
   "source": [
    "artifact_path = \"labels.json\"\n",
    "local_path = client.download_artifacts(best_version.run_id, artifact_path)\n",
    "\n",
    "print(f\"Class labels downloaded to: {local_path}\")\n",
    "\n",
    "# Load the class labels\n",
    "with open(local_path, 'r') as f:\n",
    "    class_labels = json.load(f)\n",
    "\n",
    "# Save to a new file for production use\n",
    "output_labels_path = f\"{onnx_model_path.replace('.onnx', '')}_labels.json\"\n",
    "with open(output_labels_path, 'w') as f:\n",
    "    json.dump(class_labels, f, indent=2)\n",
    "\n",
    "print(f\"Class labels saved to {output_labels_path}\")\n",
    "\n",
    "best_params = client.get_run(best_version.run_id).data.params\n",
    "best_params_path = f\"{onnx_model_path.replace('.onnx', '')}_params.json\"\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "\n",
    "print(f\"Params saved to {output_labels_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
