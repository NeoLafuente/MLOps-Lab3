{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a53650b-578b-4a8d-a068-45a04085d941",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24d68e5-a3e9-40fe-a2ff-043064c6d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fb3f6-a96a-4a3d-af3e-cf76b6790fd4",
   "metadata": {},
   "source": [
    "# Query of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c262c8c9-e625-4071-98ec-8a2f7f1fa1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 20:58:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/14 20:58:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/14 20:58:17 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/14 20:58:17 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2025/12/14 20:58:17 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/14 20:58:17 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow client\n",
    "client = MlflowClient()\n",
    "MODEL_NAME = Config.MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fc10b0-3be5-4439-a8e5-98ec9b18d3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/14 20:58:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/12/14 20:58:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "2025/12/14 20:58:17 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2025/12/14 20:58:17 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 registered model versions\n",
      "Version 6 - Run ID: 0bf33d7bf6dd49f28bcf7ed6a303bfed\n",
      "Version 5 - Run ID: d03735a2502542bcadfd5a761b64e0a9\n",
      "Version 4 - Run ID: 4b5aa21e4b584a1da5edac84e4d80710\n",
      "Version 3 - Run ID: 481696f1fed245b8950fff507181bbf8\n",
      "Version 2 - Run ID: 78fc84fa9f5447dc8b5b37d47474a3e7\n",
      "Version 1 - Run ID: c84f294d9f1d47a292d25912c4c1c030\n"
     ]
    }
   ],
   "source": [
    "# Get all versions of the registered model\n",
    "model_versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "\n",
    "print(f\"Found {len(model_versions)} registered model versions\")\n",
    "for version in model_versions:\n",
    "    print(f\"Version {version.version} - Run ID: {version.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752459ea-a089-413b-a08d-6c6d6d48726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 6 - Run ID: 0bf33d7bf6dd49f28bcf7ed6a303bfed - Test Acc: 0.9875\n",
      "Version 5 - Run ID: d03735a2502542bcadfd5a761b64e0a9 - Test Acc: 0.9891\n",
      "Version 4 - Run ID: 4b5aa21e4b584a1da5edac84e4d80710 - Test Acc: 0.9891\n",
      "Version 3 - Run ID: 481696f1fed245b8950fff507181bbf8 - Test Acc: 0.9907\n",
      "Version 2 - Run ID: 78fc84fa9f5447dc8b5b37d47474a3e7 - Test Acc: 0.9891\n",
      "Version 1 - Run ID: c84f294d9f1d47a292d25912c4c1c030 - Test Acc: 0.9876\n",
      "\n",
      "Best model: Version 3\n",
      "Run ID: 481696f1fed245b8950fff507181bbf8\n",
      "Test Accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "best_version = None\n",
    "best_f1_score = -1\n",
    "\n",
    "for version in model_versions:\n",
    "    run_id = version.run_id\n",
    "    run = client.get_run(run_id)\n",
    "    metrics = run.data.metrics\n",
    "    \n",
    "    # Get metrics\n",
    "    test_f1_score = metrics.get('test_f1_score', -1)\n",
    "    \n",
    "    print((\n",
    "        f\"Version {version.version} - \"\n",
    "        f\"Run ID: {run_id} - \"\n",
    "        f\"Test Acc: {test_f1_score:.4f}\"\n",
    "    ))\n",
    "    \n",
    "    if test_f1_score > best_f1_score:\n",
    "        best_f1_score = test_f1_score\n",
    "        best_version = version\n",
    "\n",
    "print(f\"\\nBest model: Version {best_version.version}\")\n",
    "print(f\"Run ID: {best_version.run_id}\")\n",
    "print(f\"Test Accuracy: {best_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49375365-7e44-4252-9128-7b5aaa99619a",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f031a26-58de-4496-8c45-1fae16346eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe4a1cdef2f4d9681cf382267b29b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85706eea9c5542cbb2ae3ad8593bf23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and moved to CPU\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_uri = f\"runs:/{best_version.run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "\n",
    "# Move to CPU and set to evaluation mode\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully and moved to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28debf5-e0c6-43ca-b17f-57d144f7d2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85074/212904453.py:6: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to embedded format...\n",
      "Model serialized to cats_and_dogs_mobilenet_v2_481696.onnx (embedded weights)\n"
     ]
    }
   ],
   "source": [
    "# dummy input for ONNX export\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export to ONNX\n",
    "onnx_model_path = f\"{Config.MODEL_NAME}_{best_version.run_id[0:6]}.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_model_path,\n",
    "    export_params=True,\n",
    "    opset_version=18,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "# Convert external data to embedded format\n",
    "print(\"Converting to embedded format...\")\n",
    "onnx_model = onnx.load(onnx_model_path, load_external_data=True)\n",
    "onnx.save(onnx_model, onnx_model_path)\n",
    "\n",
    "# Remove the external data file if it exists\n",
    "external_data_path = onnx_model_path + \".data\"\n",
    "if os.path.exists(external_data_path):\n",
    "    os.remove(external_data_path)\n",
    "    print(f\"Removed {external_data_path}\")\n",
    "\n",
    "print(f\"Model serialized to {onnx_model_path} (embedded weights)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b7c3c-cda9-4ad3-9939-e748a9fb0333",
   "metadata": {},
   "source": [
    "# Class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be33859b-65c9-45cc-a8de-d722bc7a3e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6a16ac4608410395f4622a86a703fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels downloaded to: /tmp/tmphqrzfqe3/labels.json\n",
      "Class labels saved to cats_and_dogs_mobilenet_v2_481696_labels.json\n",
      "Params saved to cats_and_dogs_mobilenet_v2_481696_labels.json\n"
     ]
    }
   ],
   "source": [
    "artifact_path = \"labels.json\"\n",
    "local_path = client.download_artifacts(best_version.run_id, artifact_path)\n",
    "\n",
    "print(f\"Class labels downloaded to: {local_path}\")\n",
    "\n",
    "# Load the class labels\n",
    "with open(local_path, 'r') as f:\n",
    "    class_labels = json.load(f)\n",
    "\n",
    "# Save to a new file for production use\n",
    "output_labels_path = f\"{onnx_model_path.replace('.onnx', '')}_labels.json\"\n",
    "with open(output_labels_path, 'w') as f:\n",
    "    json.dump(class_labels, f, indent=2)\n",
    "\n",
    "print(f\"Class labels saved to {output_labels_path}\")\n",
    "\n",
    "best_params = client.get_run(best_version.run_id).data.params\n",
    "best_params_path = f\"{onnx_model_path.replace('.onnx', '')}_params.json\"\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "\n",
    "print(f\"Params saved to {output_labels_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
